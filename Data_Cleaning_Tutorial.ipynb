{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebtisamasiri/T5-Data-Science-AI-Practice/blob/main/Data_Cleaning_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K1F-oY4BI45P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "flVvYrsJwO3T",
        "outputId": "fcfa24ae-10e5-4709-eb89-d67d4081fc52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "BzrLQRRGTdu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/Titanic-Dataset.csv')"
      ],
      "metadata": {
        "id": "bc3UPU7AKzKG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Null Values"
      ],
      "metadata": {
        "id": "0OFnt7E-Tkgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values (1 line)\n",
        "null_values = df.isnull().sum()\n",
        "print(null_values)"
      ],
      "metadata": {
        "id": "tCRLPInPK3ro",
        "outputId": "6bdd4cc3-e752-407c-d120-9864bd594292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill null values for 'Embarked' with the mode(1 line)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "4fN17jTOwySt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columnss with null values in 'Cabin' (or alternatively, you can fill it with a placeholder) (1 line)\n",
        "df.dropna(subset=['Cabin'], inplace=True)"
      ],
      "metadata": {
        "id": "hQ7vlK3cxCGB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Duplicates"
      ],
      "metadata": {
        "id": "ymFhv83FV80H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates (1 line)\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "HzmNbIDuLmEw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates if any (1 line)\n",
        "duplicate_rows = df.duplicated().sum()\n",
        "print(f'No of rows: {duplicate_rows}')"
      ],
      "metadata": {
        "id": "L-Xrh7XmxSkc",
        "outputId": "0f33f4dd-6d0d-4575-bc36-02451fe8f3f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Outliers"
      ],
      "metadata": {
        "id": "RkPW85MbV_8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to remove outliers using the IQR method\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]"
      ],
      "metadata": {
        "id": "NsffaZ2DL06B"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers from 'Fare' using the remove_outilers function (1 line)\n",
        "df = remove_outliers(df, 'Fare')\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "ovzIdtcyxgxc",
        "outputId": "77c75a76-408f-4f1c-d75b-74d53f1765e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   186.000000  186.000000  186.000000  168.000000  186.000000   \n",
            "mean    453.053763    0.661290    1.215054   36.389405    0.403226   \n",
            "std     251.814319    0.474548    0.547218   15.852214    0.534021   \n",
            "min       2.000000    0.000000    1.000000    0.920000    0.000000   \n",
            "25%     254.250000    0.000000    1.000000   25.000000    0.000000   \n",
            "50%     457.500000    1.000000    1.000000   36.000000    0.000000   \n",
            "75%     668.250000    1.000000    1.000000   48.000000    1.000000   \n",
            "max     890.000000    1.000000    3.000000   80.000000    2.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  186.000000  186.000000  \n",
            "mean     0.354839   57.791443  \n",
            "std      0.634932   37.807084  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000   26.842700  \n",
            "50%      0.000000   52.554200  \n",
            "75%      1.000000   79.650000  \n",
            "max      2.000000  153.462500  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling and Normalization"
      ],
      "metadata": {
        "id": "kOTEDjprUiwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Standard scaling for 'Fare' (2 lines)\n",
        "scaler = StandardScaler()\n",
        "df['Fare'] = scaler.fit_transform(df[['Fare']])"
      ],
      "metadata": {
        "id": "k3AaqNXcTaDR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-Max scaling for 'Age' (2 lines)\n",
        "scaler = MinMaxScaler()\n",
        "df['Age'] = scaler.fit_transform(df[['Age']])"
      ],
      "metadata": {
        "id": "ThXHDyLTxzfT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Categorical Variables"
      ],
      "metadata": {
        "id": "ETtUvmP3Uz1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding for 'Embarked' and 'Sex' (1 line)\n",
        "df = pd.get_dummies(df, columns=['Embarked', 'Sex'])"
      ],
      "metadata": {
        "id": "OxjK9FbhU4oq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "KyLn4Y_myBcb",
        "outputId": "a3834d2a-f6e0-4a51-b01f-505673820ba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     PassengerId  Survived  Pclass  \\\n",
            "1              2         1       1   \n",
            "3              4         1       1   \n",
            "6              7         0       1   \n",
            "10            11         1       3   \n",
            "11            12         1       1   \n",
            "..           ...       ...     ...   \n",
            "871          872         1       1   \n",
            "872          873         0       1   \n",
            "879          880         1       1   \n",
            "887          888         1       1   \n",
            "889          890         1       1   \n",
            "\n",
            "                                                  Name       Age  SibSp  \\\n",
            "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  0.468892      1   \n",
            "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  0.430956      1   \n",
            "6                              McCarthy, Mr. Timothy J  0.671219      0   \n",
            "10                     Sandstrom, Miss. Marguerite Rut  0.038948      1   \n",
            "11                            Bonnell, Miss. Elizabeth  0.721801      0   \n",
            "..                                                 ...       ...    ...   \n",
            "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  0.582701      1   \n",
            "872                           Carlsson, Mr. Frans Olof  0.405665      0   \n",
            "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  0.696510      0   \n",
            "887                       Graham, Miss. Margaret Edith  0.228629      0   \n",
            "889                              Behr, Mr. Karl Howell  0.317147      0   \n",
            "\n",
            "     Parch    Ticket      Fare        Cabin  Embarked_C  Embarked_Q  \\\n",
            "1        0  PC 17599  0.357824          C85        True       False   \n",
            "3        0    113803 -0.124424         C123       False       False   \n",
            "6        0     17463 -0.157244          E46       False       False   \n",
            "10       1   PP 9549 -1.089805           G6       False       False   \n",
            "11       0    113783 -0.828569         C103       False       False   \n",
            "..     ...       ...       ...          ...         ...         ...   \n",
            "871      1     11751 -0.138899          D35       False       False   \n",
            "872      0       695 -1.400106  B51 B53 B55       False       False   \n",
            "879      1     11767  0.672766          C50        True       False   \n",
            "887      0    112053 -0.737070          B42       False       False   \n",
            "889      0    111369 -0.737070         C148        True       False   \n",
            "\n",
            "     Embarked_S  Sex_female  Sex_male  \n",
            "1         False        True     False  \n",
            "3          True        True     False  \n",
            "6          True       False      True  \n",
            "10         True        True     False  \n",
            "11         True        True     False  \n",
            "..          ...         ...       ...  \n",
            "871        True        True     False  \n",
            "872        True       False      True  \n",
            "879       False        True     False  \n",
            "887        True        True     False  \n",
            "889       False       False      True  \n",
            "\n",
            "[186 rows x 15 columns]\n"
          ]
        }
      ]
    }
  ]
}